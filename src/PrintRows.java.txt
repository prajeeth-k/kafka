import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.clients.consumer.ConsumerRebalanceListener;
import org.apache.kafka.common.errors.WakeupException;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serdes;

import java.util.Collection;
import java.lang.String;
import java.util.ConcurrentModificationException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.time.Duration;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Properties;
import java.util.Map;
import java.util.HashMap;

@SuppressWarnings("unchecked")
class KeyDeserializer1 implements Deserializer<String> {
   Map<String, String> deserial;
   KeyDeserializer1 () {
      deserial = new HashMap<String, String>();
      deserial.put ("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
   }
   //void configure (Map<String,String> deserial, boolean isKeytrue) {}
   @Override public void configure(Map<String, ?> arg0, boolean arg1) {}
   @Override
   public String deserialize (String topic, byte[] data) {
        String x = new String (data);
        return x;
   }
   @Override public void close () {}
}

@SuppressWarnings("unchecked")
class ValueDeserializer1 implements Deserializer<String> {
   Map<String, String> deserial;
   ValueDeserializer1 () {
      deserial = new HashMap<String, String>();
      deserial.put ("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
   }
   // void configure (Map<String,String> deserial, boolean isKeytrue) {}
   @Override public void configure(Map<String, ?> arg0, boolean arg1) {}
   @Override
   public String deserialize (String topic, byte[] data) {
        String x = new String (data);
        return x;
   }
   @Override public void close () {}
}

@SuppressWarnings("unchecked")
public class PrintRows {

   Properties props;
   KeyDeserializer1 k;
   ValueDeserializer1 v;
   public void printRows () {
        k = new KeyDeserializer1 ();
        v = new ValueDeserializer1 ();
        //public void subscribe (Arrays.asList ("topic1"), ConsumerRebalanceListener listener) {}
   }
   public void kafkaConsumer () {
      final AtomicBoolean closed = new AtomicBoolean(false);
      props = new Properties();
      props.setProperty ("bootstrap.servers", "localhost:9092");
      props.setProperty("group.id", "test");
      props.setProperty("enable.auto.commit", "false");
      props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
      props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
      String pVal = props.getProperty ("key.deserializer");
      System.out.println ("--------> Key : " + pVal);
      KafkaConsumer<String, String> consumer = new KafkaConsumer<> (props);
      consumer.subscribe (Arrays.asList ("topic1"));
      final int minBatchSize = 200;
      List<ConsumerRecord<String, String>> buffer = new ArrayList<>();
      while (!closed.get()) {
         ConsumerRecords<String, String> records = consumer.poll (Duration.ofMillis (100));
         for (ConsumerRecord<String, String> record : records) {
            buffer.add(record);
            System.out.println ("Topic : " + record.topic () + " | Key : " + record.key () + " | Value : " + record.value ());
         }
      }
      if (buffer.size () >= minBatchSize) {
         //insertIntoDb(buffer);
         consumer.commitSync();
         buffer.clear();
      }
   }

   public static void main (String[] a) {
      PrintRows printRows = new PrintRows ();
      printRows.kafkaConsumer ();
   }
}
---------------------------------------------------------------
# User specific environment and startup programs
export KAFKA_HOME=/opt/apache/kafka_2.13-2.6.0/
export JAVA_HOME=/u2/java/jdk1.8.0_181
export JRE_HOME=/u2/java/jdk1.8.0_181/jre
export LD_LIBRARY_PATH=$ORACLE_HOME/lib:$OGG_HOME:/u2/java/jdk1.8.0_181/jre/lib/amd64/server
#export OGG_HOME=/opt/oracle/product/goldengate19c/db12c
export CLASSPATH=.:/home/oracle/avro-1.10.0.jar:/home/oracle/:/opt/apache/kafka_2.13-2.6.0/libs/kafka-clients-2.6.0.jar:/opt/apache/kafka_2.13-2.6.0/libs/slf4j-api-1.7.30.jar
export CLASSPATH=$CLASSPATH:/opt/apache/kafka_2.13-2.6.0/libs/*
export PATH=$KAFKA_HOME/bin:$JAVA_HOME/bin:$JRE_HOME/bin:$KAFKA_HOME:$PATH

javac -Xlint PrintRows.java
java PrintRows

